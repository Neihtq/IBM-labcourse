{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from datetime import datetime\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from face_recognition.models.MetricsCallback import MetricsCallback\n",
    "from face_recognition.models.FaceNetPytorchLightning import LightningFaceNet\n",
    "from face_recognition.models.FaceNet import FaceNetResnet\n",
    "from face_recognition.data.datasets import LFWValidationDataset, TupleDataset, VGGTripletDataset\n",
    "from face_recognition.utils.constants import MODEL_DIR, CHECKPOINTS_DIR\n",
    "\n",
    "overfit_root = './face_recognition/data/images/vgg-cropped'\n",
    "lfw_root = './face_recognition/data/images/lfw_aligned'\n",
    "pairs_txt = './face_recognition/data/images/pairs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'margin': 0.2,\n",
    "    'lr': 0.0001,\n",
    "    'weight_decay': 1e-5,\n",
    "    'optimizer': 'adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(dataset, train=False):\n",
    "    batch_size = 256\n",
    "\n",
    "    phase = \"training\" if train else 'validation'\n",
    "    print(f\"Initialize {phase} dataloader.\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=20)\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def init_datasets():\n",
    "    train_dir = './face_recognition/data/images/vgg-cropped'\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.6068, 0.4517, 0.3800], std=[0.2492, 0.2173, 0.2082])\n",
    "    ])\n",
    "\n",
    "    train_set = VGGTripletDataset(train_dir, 100000, transform=transform)\n",
    "\n",
    "    val_loader = None\n",
    "    if lfw_root and pairs_txt:\n",
    "        lfw_set = LFWValidationDataset(lfw_root, pairs_txt, transform=transform)\n",
    "        len_lfw_set = int(0.2 * len(train_set)) #len(lfw_set)\n",
    "\n",
    "        len_train_set = len(train_set) - len_lfw_set\n",
    "        train_set, val_set = random_split(train_set, [len_train_set, len_lfw_set])\n",
    "\n",
    "        tuple_set = TupleDataset(lfw_set, val_set)\n",
    "        val_loader = get_dataloader(tuple_set)\n",
    "\n",
    "    train_loader = get_dataloader(train_set, train=True)\n",
    "\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "model_dir = MODEL_DIR\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "\n",
    "time_stamp = datetime.strftime(datetime.now(), '%Y%m%d-%H%M%S')\n",
    "subdir = os.path.join(model_dir, time_stamp)\n",
    "if not os.path.exists(subdir):\n",
    "    os.mkdir(subdir)\n",
    "\n",
    "train_dir = overfit_root\n",
    "if not train_dir:\n",
    "    raise ValueError('No training data specified.')\n",
    "\n",
    "train_loader, val_loader = init_datasets()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=CHECKPOINTS_DIR,\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_top_k=1\n",
    ")\n",
    "logger = TensorBoardLogger('tb_logs', name='facesecure_training')\n",
    "print(\"Initialize FaceNet + Resnet\")\n",
    "backbone = FaceNetResnet(pretrained=True)\n",
    "model = LightningFaceNet(hparams, backbone)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    max_epochs=num_epochs,\n",
    "    logger=logger,\n",
    "    #checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[MetricsCallback()]\n",
    ")\n",
    "\n",
    "print(\"Begin Training.\")\n",
    "start = timeit.default_timer()\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Finished Training in\", stop - start, \"seconds\")\n",
    "\n",
    "print(\"Save trained weights.\")\n",
    "model_name = os.path.join(subdir, time_stamp + '.pth')\n",
    "torch.save(model.model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
